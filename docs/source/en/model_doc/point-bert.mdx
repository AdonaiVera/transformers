<!--Copyright 2023 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

# Point-BERT

## Overview

The Point-BERT model was proposed in [Point-BERT: Pre-training 3D Point Cloud Transformers with
Masked Point Modeling](https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Point-BERT_Pre-Training_3D_Point_Cloud_Transformers_With_Masked_Point_Modeling_CVPR_2022_paper.pdf) by <Xumin Yu*, Lulu Tang*, Yongming Rao*, Tiejun Huang, Jie Zhou, Jiwen Lu>.
Point-BERT is a method for training Transformers on 3D point cloud data using a Masked Point Modeling task. It divides the point cloud into local patches, generates discrete point tokens with local information, and trains the Transformer to recover masked tokens. The aim is to extend BERT to 3D point cloud data.

The abstract from the paper is the following:

*Point-BERT is a new paradigm for learning Transformers to generalize the concept of BERT onto 3D point cloud. Inspired by BERT, we devise a Masked Point Modeling (MPM) task to pre-train point cloud Transformers. Specifically, we first divide a point cloud into several local patches, and a point cloud Tokenizer is devised via a discrete Variational AutoEncoder (dVAE) to generate discrete point tokens containing meaningful local information. Then, we randomly mask some patches of input point clouds and feed them into the backbone Transformer. The pre-training objective is to recover the original point tokens at the masked locations under the supervision of point tokens obtained by the Tokenizer.*

This model was contributed by [adonaivera](https://huggingface.co/adonaivera).
The original code can be found [here](https://github.com/lulutang0608/Point-BERT).


## PointBERTConfig

[[autodoc]] PointBERTConfig

## PointBERTFeatureExtractor

[[autodoc]] PointBERTFeatureExtractor
    - __call__
    - post_process_semantic_segmentation

## PointBERTImageProcessor

[[autodoc]] PointBERTImageProcessor
    - preprocess
    - post_process_semantic_segmentation

## PointBERTModel

[[autodoc]] PointBERTModel
    - forward

## PointBERTDecodeHead

[[autodoc]] PointBERTDecodeHead
    - forward

## PointBERTForImageClassification

[[autodoc]] PointBERTForImageClassification
    - forward

## PointBERTForSemanticSegmentation

[[autodoc]] PointBERTForSemanticSegmentation
    - forward
